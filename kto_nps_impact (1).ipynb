{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Path does not exist: /Users/jessevdsluis/src",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(module_path)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(module_path):\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath does not exist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdsi_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_path\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Path does not exist: /Users/jessevdsluis/src"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../..\", \"src\"))  # make sure the path is right\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "if not os.path.isdir(module_path):\n",
    "    raise FileNotFoundError(f\"Path does not exist: {module_path}\")\n",
    "\n",
    "from dsi_utils import data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingRegressor, ExplainableBoostingClassifier\n",
    "from interpret import set_visualize_provider\n",
    "from interpret.provider import InlineProvider\n",
    "from interpret import show\n",
    "\n",
    "set_visualize_provider(InlineProvider())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "gx = pl.read_excel(data_path(\"Project_KTO_2025_20250818134037.xlsx\"))\n",
    "theme_results = pl.read_excel(data_path(\"Paradigma_results.xlsx\"))\n",
    "\n",
    "# select label\n",
    "select_label = \"Resolu\"\n",
    "resolu_idx = gx[['sys_respondentId', \"Label\"]].filter(pl.col(\"Label\") == select_label)\n",
    "\n",
    "# merge results\n",
    "data = theme_results.join(resolu_idx, on=\"sys_respondentId\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onehot THEMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dsi_utils import extract_theme_subtheme_pairs, ensure_pandas, ensure_polars\n",
    "\n",
    "## Loacl definitions\n",
    "def ensure_pandas(obj: Union[pd.DataFrame, pd.Series, pl.DataFrame, pl.Series]) -> Union[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Ensure the input is a pandas DataFrame or Series.\n",
    "\n",
    "    Args:\n",
    "        obj: A pandas or polars DataFrame or Series.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame or Series.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, (pd.DataFrame, pd.Series)):\n",
    "        return obj\n",
    "    elif isinstance(obj, pl.DataFrame):\n",
    "        if obj.width == 1:\n",
    "            return obj.to_series().to_pandas()\n",
    "        else:\n",
    "            return obj.to_pandas()\n",
    "    elif isinstance(obj, pl.Series):\n",
    "        return obj.to_pandas()\n",
    "    else:\n",
    "        raise TypeError(f\"Expected a Polars or Pandas DataFrame/Series, got {type(obj)}\")\n",
    "\n",
    "\n",
    "def ensure_polars(obj: Union[pd.DataFrame, pd.Series, pl.DataFrame, pl.Series]) -> Union[pl.DataFrame, pl.Series]:\n",
    "    \"\"\"\n",
    "    Ensure the input is a Polars DataFrame or Series.\n",
    "\n",
    "    Args:\n",
    "        obj: A pandas or polars DataFrame or Series.\n",
    "\n",
    "    Returns:\n",
    "        A Polars DataFrame or Series.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, (pl.DataFrame, pl.Series)):\n",
    "        return obj\n",
    "    elif isinstance(obj, pd.DataFrame):\n",
    "        return pl.from_pandas(obj)\n",
    "    elif isinstance(obj, pd.Series):\n",
    "        return pl.Series(name=obj.name or \"value\", values=obj.values)\n",
    "    else:\n",
    "        raise TypeError(f\"Expected a Polars or Pandas DataFrame/Series, got {type(obj)}\")\n",
    "\n",
    "\n",
    "\n",
    "def extract_theme_subtheme_pairs(\n",
    "    themes_json: str,\n",
    "    GX_themes: dict,\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Extracts valid theme-subtheme pairs from a JSON string, based on GX_themes mapping.\n",
    "\n",
    "    Args:\n",
    "        themes_json (str): JSON string with theme/subtheme keys and feedback values.\n",
    "        GX_themes (dict): Dictionary mapping main themes to lists of valid subthemes.\n",
    "\n",
    "    Returns:\n",
    "        list: List of valid \"Main theme > Subtheme\" strings found in the feedback.\n",
    "    \"\"\"\n",
    "    if pd.isnull(themes_json):\n",
    "        return []\n",
    "    try:\n",
    "        themes_dict = json.loads(themes_json)\n",
    "        pairs = []\n",
    "\n",
    "        # Process each theme in the JSON\n",
    "        for theme_key, theme_value in themes_dict.items():\n",
    "            # Extract main theme (part before \">\")\n",
    "            main_theme = theme_key.split(\" > \")[0].strip()\n",
    "\n",
    "            # If there's a subtheme mentioned in the key (after \">\")\n",
    "            if \" > \" in theme_key:\n",
    "                subtheme = theme_key.split(\" > \")[1].strip()\n",
    "                # Check if this is a valid combination according to GX_themes\n",
    "                if main_theme in GX_themes and isinstance(GX_themes[main_theme], list):\n",
    "                    if subtheme in GX_themes[main_theme]:\n",
    "                        pairs.append(f\"{main_theme} > {subtheme}\")\n",
    "\n",
    "            # If no subtheme in key, check all subthemes from GX_themes for this main theme\n",
    "            elif main_theme in GX_themes:\n",
    "                if isinstance(GX_themes[main_theme], list):\n",
    "                    # Add mentioned subthemes from actual feedback text\n",
    "                    for subtheme in GX_themes[main_theme]:\n",
    "                        # Simple check if this subtheme is mentioned in the feedback value\n",
    "                        feedback_text = str(theme_value).lower()\n",
    "                        subtheme_text = subtheme.lower()\n",
    "                        if subtheme_text in feedback_text:\n",
    "                            pairs.append(f\"{main_theme} > {subtheme}\")\n",
    "\n",
    "        return pairs\n",
    "    except Exception:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gx_thema_structuur = {\n",
    "    \"Dienstverlening\": [\n",
    "        \"Breedte dienstverlening & aansluiten op behoeften\",\n",
    "        \"Kwaliteit van dienstverlening\",\n",
    "        \"Prijs-kwaliteit verhouding (value for money)\",\n",
    "        \"Schaalbaarheid van prijzen & meerwerk\",\n",
    "        \"Consistentie & betrouwbaarheid\",\n",
    "    ],\n",
    "    \"Samenwerking & partnership\": [\n",
    "        \"Vertrouwen\",\n",
    "        \"Gelijkwaardigheid & wederkerigheid\",\n",
    "        \"Ontzorgen & meedenken\",\n",
    "        \"Persoonlijk contact (Relatie met contactpersoon)\",\n",
    "        \"Pro-activiteit\",\n",
    "        \"Aanpassingsvermogen & flexibiliteit\",\n",
    "    ],\n",
    "    \"Communicatie & Informatievoorziening\": [\n",
    "        \"Operationele communicatie\",\n",
    "        \"Branchekennis en ontwikkelingen\",\n",
    "        \"Best practices\",\n",
    "        \"Strategische communicatie\",\n",
    "        \"Transparantie\",\n",
    "    ],\n",
    "    \"Werking organisatie\": [\n",
    "        \"Procedures, processen, systemen\",\n",
    "        \"Voldoen aan wet- en regelgeving\",\n",
    "        \"Administratieve afhandeling\",\n",
    "        \"Personeelsbeleid & stabiliteit\",\n",
    "    ],\n",
    "    \"Medewerkers\": [\n",
    "        \"Kennis\",\n",
    "        \"Professionaliteit\",\n",
    "        \"Flexibiliteit\",\n",
    "        \"Klantgedrevenheid\",\n",
    "        \"Verlengstuk zijn van organisatie\",\n",
    "        \"Bereikbaarheid\",\n",
    "        \"Nakomen afspraken\",\n",
    "    ],\n",
    "    \"Verbeteren en innoveren\": [\n",
    "        \"Feedback & verbeterprocessen\",\n",
    "        \"Oplossen van problemen en klachten\",\n",
    "        \"Continue ontwikkeling van bestaande en nieuwe diensten\",\n",
    "    ],\n",
    "    \"Visie organisatie\": [\n",
    "        \"Duurzaamheid\",\n",
    "        \"Welzijn\",\n",
    "    ],\n",
    "    # \"Overig\": [\n",
    "    #     \"Geen relevante informatie\",\n",
    "    # ],\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thema_structuur = gx_thema_structuur\n",
    "\n",
    "def extract_theme_lst(theme_str):\n",
    "  themes = []\n",
    "  if theme_str is not None:\n",
    "      themes = extract_theme_subtheme_pairs(theme_str, thema_structuur)\n",
    "  return themes\n",
    "\n",
    "def count_themes(nested_list):\n",
    "    from collections import Counter\n",
    "    flat_list = [item for sublist in nested_list for item in sublist]  # Flatten the nested list\n",
    "    return Counter(flat_list)\n",
    "\n",
    "def all_themes_col(df):\n",
    "  df = ensure_pandas(df)\n",
    "  themes_list = []\n",
    "  for theme in df:\n",
    "      themes_list.append(extract_theme_subtheme_pairs(theme, thema_structuur))\n",
    "  return set([item for sublist in themes_list for item in sublist]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ensure_pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mensure_pandas\u001b[49m(data)\n\u001b[1;32m      2\u001b[0m theme_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(all_themes_col(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTHEMES\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m      3\u001b[0m nested_themes \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTHEMES\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(extract_theme_lst)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ensure_pandas' is not defined"
     ]
    }
   ],
   "source": [
    "data = ensure_pandas(data)\n",
    "theme_names = list(all_themes_col(data['THEMES']))\n",
    "nested_themes = data['THEMES'].apply(extract_theme_lst)\n",
    "one_hot_encoded_themes = nested_themes.apply(lambda x: pd.Series(1, index=x)).fillna(0)\n",
    "data = pd.concat([data, one_hot_encoded_themes], axis=1)\n",
    "data.drop(columns=['THEMES'], inplace=True) \n",
    "data = ensure_polars(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = \"sys_respondentId\"\n",
    "data = data[[ID, 'NPS', 'comments'] + theme_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KPI prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dsi_utils import nps_to_type\n",
    "# from feature_importance.utils import theme_contains\n",
    "# from dsi_utils import get_main_themes, add_main_theme_onehots, filter_at_least_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Helper functions local:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnps_to_type\u001b[39m(\n\u001b[0;32m----> 4\u001b[0m     df: \u001b[43mpl\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame, nps_score_col: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNPS_score\u001b[39m\u001b[38;5;124m'\u001b[39m, nps_type_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNPS\u001b[39m\u001b[38;5;124m'\u001b[39m, standard: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuropean\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pl\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    Convert NPS score to type (-100, 0, 100)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m        pl.DataFrame: Input dataframe with NPS type column\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m standard \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuropean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pl' is not defined"
     ]
    }
   ],
   "source": [
    "## Helper functions local:\n",
    "\n",
    "def nps_to_type(\n",
    "    df: pl.DataFrame, nps_score_col: str = 'NPS_score', nps_type_name: str = 'NPS', standard: str = \"european\"\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert NPS score to type (-100, 0, 100)\n",
    "    Args:\n",
    "        df (pl.DataFrame): Input dataframe\n",
    "        nps_score_col (str): Name of the NPS score column\n",
    "        nps_type_name (str): Name of the NPS type column\n",
    "        standard (str): Standard of the NPS score (european or american)\n",
    "    Returns:\n",
    "        pl.DataFrame: Input dataframe with NPS type column\n",
    "    \"\"\"\n",
    "    if standard == \"european\":\n",
    "        return df.with_columns(\n",
    "            [\n",
    "                pl.when(pl.col(nps_score_col) <= 5)\n",
    "                .then(-100)\n",
    "                .when(pl.col(nps_score_col) <= 7)\n",
    "                .then(0)\n",
    "                .when(pl.col(nps_score_col) <= 10)\n",
    "                .then(100)\n",
    "                .otherwise(None)\n",
    "                .alias(nps_type_name)\n",
    "            ]\n",
    "        )\n",
    "    elif standard == \"american\":\n",
    "        return df.with_columns(\n",
    "            [\n",
    "                pl.when(pl.col(nps_score_col) <= 6)\n",
    "                .then(-100)\n",
    "                .when(pl.col(nps_score_col) <= 8)\n",
    "                .then(0)\n",
    "                .when(pl.col(nps_score_col) <= 10)\n",
    "                .then(100)\n",
    "                .otherwise(None)\n",
    "                .alias(nps_type_name)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "def theme_contains(containing: str, feature_list: list[str]) -> list[str]:\n",
    "    return [feature for feature in feature_list if containing.lower() in feature.lower()]\n",
    "\n",
    "\n",
    "def get_main_themes(theme_names: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract distinct main themes from strings like 'main_theme > sub_theme',\n",
    "    preserving first-seen order.\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for s in theme_names:\n",
    "        main = s.split(\">\", 1)[0].strip()\n",
    "        if main and main not in seen:\n",
    "            seen.add(main)\n",
    "            result.append(main)\n",
    "    return result\n",
    "\n",
    "\n",
    "def add_main_theme_onehots(\n",
    "    df: pl.DataFrame,\n",
    "    theme_names: list[str],\n",
    "    output_dtype: pl.DataType = pl.Float64,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    For one-hot subtheme columns named 'main > sub', add/overwrite main-theme\n",
    "    one-hot columns. A main theme is 1 if any of its subthemes is 1.\n",
    "    Missing subtheme columns are ignored. Nulls treated as 0.\n",
    "    \"\"\"\n",
    "    # group subtheme columns by main theme, keep only columns present in df\n",
    "    groups = defaultdict(list)\n",
    "    for s in theme_names:\n",
    "        main = s.split(\">\", 1)[0].strip()\n",
    "        if s in df.columns:\n",
    "            groups[main].append(s)\n",
    "\n",
    "    # build expressions: OR across each group's columns\n",
    "    new_cols = []\n",
    "    for main, cols in groups.items():\n",
    "        if not cols:\n",
    "            continue\n",
    "        any_sub = pl.sum_horizontal([pl.col(c).fill_null(0).cast(pl.Int8) for c in cols]) > 0\n",
    "        out = any_sub if output_dtype == pl.Boolean else pl.when(any_sub).then(1).otherwise(0).cast(output_dtype)\n",
    "        new_cols.append(out.alias(main))\n",
    "\n",
    "    return df.with_columns(new_cols)\n",
    "\n",
    "\n",
    "def filter_at_least_onehot(df: pl.DataFrame, one_hot_cols: list[str]) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Keep rows where at least one of the given one-hot columns equals 1.\n",
    "    Nulls are treated as 0. Missing columns are ignored.\n",
    "    \"\"\"\n",
    "    cols = [c for c in one_hot_cols if c in df.columns]\n",
    "    if not cols:\n",
    "        return df\n",
    "\n",
    "    any_one = pl.sum_horizontal([pl.col(c).fill_null(0).cast(pl.Int8) for c in cols]) > 0\n",
    "    return df.filter(any_one)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nps_to_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnps_to_type\u001b[49m(data, nps_score_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNPS\u001b[39m\u001b[38;5;124m'\u001b[39m, nps_type_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNPS\u001b[39m\u001b[38;5;124m'\u001b[39m, standard\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamerican\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print class imbalance\u001b[39;00m\n\u001b[1;32m      4\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNPS\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nps_to_type' is not defined"
     ]
    }
   ],
   "source": [
    "data = nps_to_type(data, nps_score_col='NPS', nps_type_name='NPS', standard='american')\n",
    "\n",
    "# print class imbalance\n",
    "data['NPS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filter_at_least_onehot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_at_least_onehot\u001b[49m(data, theme_names)\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m add_main_theme_onehots(data, theme_names)\n\u001b[1;32m      4\u001b[0m data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filter_at_least_onehot' is not defined"
     ]
    }
   ],
   "source": [
    "data = filter_at_least_onehot(data, theme_names)\n",
    "data = add_main_theme_onehots(data, theme_names)\n",
    "\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_main_themes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m main_themes \u001b[38;5;241m=\u001b[39m \u001b[43mget_main_themes\u001b[49m(theme_names)\n\u001b[1;32m      2\u001b[0m main_themes\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_main_themes' is not defined"
     ]
    }
   ],
   "source": [
    "main_themes = get_main_themes(theme_names)\n",
    "main_themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: expecting '}' (4244452977.py, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [12], line 36\u001b[0;36m\u001b[0m\n\u001b[0;31m    text=[f\"{int(round(pct_neg,1))}%{\"<br>Niet benoemd\" if niet_label else \"\"}\"],\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: expecting '}'\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def divergent_comparative_bar_chart(theme_name,\n",
    "                                    not_mentioned_score, not_mentioned_n,\n",
    "                                    mentioned_score, mentioned_n,\n",
    "                                    custom_thema_title=None,\n",
    "                                    x_name='gast-NPS', niet_label=True, thema_label=True):\n",
    "\n",
    "    # Clean up theme\n",
    "    theme = theme_name.split(\"> \")[-1].strip()\n",
    "    title_theme = custom_thema_title or theme\n",
    "\n",
    "    # Totals & percentages\n",
    "    total = mentioned_n + not_mentioned_n\n",
    "    pct_pos = mentioned_n / total * 100\n",
    "    pct_neg = not_mentioned_n / total * 100\n",
    "    total_effect = mentioned_score - not_mentioned_score\n",
    "\n",
    "    # decide colors\n",
    "    pos_color = '#005444'\n",
    "    neg_color = '#DE5912'\n",
    "    mentioned_color = pos_color if mentioned_score >= 0 else neg_color\n",
    "    mentioned_color2 = pos_color if mentioned_score < 0 else neg_color\n",
    "\n",
    "    # Build the figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Negative bar (orange), base at 0, extending left\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[not_mentioned_score],\n",
    "        y=[theme],\n",
    "        orientation='h',\n",
    "        base=0,\n",
    "        marker_color=mentioned_color2,\n",
    "        name=\"Niet benoemd\",\n",
    "        text=[f\"{int(round(pct_neg,1))}%{\"<br>Niet benoemd\" if niet_label else \"\"}\"],\n",
    "        textposition='inside',\n",
    "        insidetextanchor='middle',\n",
    "        marker_line=dict(color='gray', width=1),\n",
    "    ))\n",
    "\n",
    "    # Thema benoemd bar, color based on its sign\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[mentioned_score],\n",
    "        y=[theme],\n",
    "        orientation='h',\n",
    "        base=0,\n",
    "        marker_color=mentioned_color,\n",
    "        name=\"Thema benoemd\",\n",
    "        text=[f\"{int(round(pct_pos,1))}%{\"<br>Thema benoemd\" if thema_label else \"\"}\"],\n",
    "        textposition='inside',\n",
    "        insidetextanchor='middle',\n",
    "        marker_line=dict(color='gray', width=1),\n",
    "    ))\n",
    "\n",
    "    # Layout tweaks\n",
    "    fig.update_layout(\n",
    "        barmode='stack',  # stack from zero\n",
    "        title={\n",
    "            'text': f\"Thema: <b>{title_theme}</b>\",\n",
    "            'x': 0.5, 'xanchor': 'center',\n",
    "            'y': 0.8\n",
    "        },\n",
    "        xaxis=dict(\n",
    "            title=f'Verwacht effect op {x_name} (n = {total})',\n",
    "            zeroline=True, zerolinewidth=2, zerolinecolor='black'\n",
    "        ),\n",
    "        yaxis=dict(showticklabels=False),\n",
    "        showlegend=False,\n",
    "        margin=dict(l=50, r=30, t=70, b=80),\n",
    "        annotations=[dict(\n",
    "            text=f\"<b>[ Totale effect: {total_effect:.1f} punten ]</b>\",\n",
    "            xref='paper', yref='paper',\n",
    "            x=0.5, y=-1.15, showarrow=False\n",
    "        )],\n",
    "        template='plotly_white',\n",
    "        height=210, width=550,\n",
    "        font=dict(family=\"Arial, sans-serif\", size=12),\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LET OP!\n",
    "gewogen op NPS-type: MAAR 6 detractors (wegen dus heel zwaar op 109 responses)\n",
    "\n",
    "TODO:\n",
    "- Filter op minimaal aantal benoemd afhankelijk van NPS type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ensure_pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mensure_pandas\u001b[49m(data[theme_names]) \u001b[38;5;66;03m#main_themes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m ensure_pandas(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNPS\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#w = compute_balanced_weights(data[\"NPS\"])\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#ebm = ExplainableBoostingClassifier(\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ensure_pandas' is not defined"
     ]
    }
   ],
   "source": [
    "X = ensure_pandas(data[theme_names]) #main_themes\n",
    "y = ensure_pandas(data[\"NPS\"])\n",
    "#w = compute_balanced_weights(data[\"NPS\"])\n",
    "\n",
    "#ebm = ExplainableBoostingClassifier(\n",
    "ebm = ExplainableBoostingRegressor(\n",
    "    interactions=1, \n",
    ")\n",
    "ebm.fit(X, y)#, sample_weight=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_global = ebm.explain_global()\n",
    "show(ebm_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature name (see which feature numbers in ebm_global visualisation!)\n",
    "n_feature = 23\n",
    "feature_name = ebm.term_names_[n_feature]\n",
    "\n",
    "divergent_comparative_bar_chart(\n",
    "    theme_name=feature_name,\n",
    "    not_mentioned_score=ebm.term_scores_[n_feature][1], not_mentioned_n=len(X[X[feature_name] == 0]),\n",
    "    mentioned_score=ebm.term_scores_[n_feature][2], mentioned_n=len(X[X[feature_name] == 1]),\n",
    "    #custom_thema_title=\"Kennis van medewerker\", \n",
    "    x_name=\"NPS\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: print betrouwbaarheids interval onder plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results\n",
    "sub + main themes (unweighted, with 1st interactions)\n",
    "#### Pos\n",
    "1. Samenwerking & partnerschap > Persoonlijk contact (relatie met contactpersoon)\n",
    "2. Medewerkers (hoofd thema)\n",
    "3. Medewerkers > Kennis\n",
    "\n",
    "#### Neg\n",
    "1. Samenwerking & partnerschap (hoofd thema)\n",
    "2. Verbeteren & innoveren (hoofd thema -> sterkste subthema: oplossen van problemen en klachten)\n",
    "3. Communicatie & informatie verziening (hoofd thema)\n",
    "\n",
    "---\n",
    "only main themas (weighted by nps type, 1st interactions)\n",
    "> 1. Communicatie en infromatievoorziening\n",
    "> 2. verbeteren en innoveren\n",
    "> 3. samenwerking en partnership\n",
    "\n",
    "unweighted -->\n",
    "1. Communicatie en infromatievoorziening (neg)\n",
    "2. Werking organisatie (neg)\n",
    "3. verbeteren en innoveren (neg)\n",
    "4. Medw. (pos)\n",
    "5. samenwerking (pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_contains('continue', theme_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.filter(pl.col('Verbeteren en innoveren > Continue ontwikkeling van bestaande en nieuwe diensten') == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in \tdata.filter(pl.col('Verbeteren en innoveren > Continue ontwikkeling van bestaande en nieuwe diensten') == 1)['comments'].to_list():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_importance.actionable_ml import AML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ensure_pandas(data[theme_names + main_themes])\n",
    "y = ensure_pandas(data[\"NPS\"])\n",
    "w = None #compute_balanced_weights(data[\"NPS\"])\n",
    "interactions = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = AML(\n",
    "  X, y, w, \n",
    "  actionable_features=theme_names + main_themes,\n",
    "  #support_args={'min_total': 5, 'min_per_class': 0, 'regression': False, 'min_minority': 2, 'override_class': '-100'}, \n",
    "  support_args={'min_total': 5, 'min_per_class': 0, 'regression': True, 'min_minority': 2, 'override_class': '-100'}, \n",
    "  ebm_kwargs={'interactions': interactions}, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml.actionable_effects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_importance import ActionablePlots\n",
    "\n",
    "plt = ActionablePlots(aml)\n",
    "kpi = \"NPS\"\n",
    "\n",
    "fig_effect = plt.plot_delta_feature_ieffect(\n",
    "  top_n=15, \n",
    "  sort_type=\"importance\", \n",
    "  kpi_name=kpi, \n",
    "  flip_colors=True,\n",
    "  title = f\"Effect van klant-drivers op {kpi} (in Δ%)\"#<br>(gesorteerd op feature importance)\"\n",
    ") #Δ\n",
    "\n",
    "fig_importance = plt.plot_feature_importance(top_k=50, quantile=0.0, actionable=True, height=600)\n",
    "\n",
    "feature_name = 'Vitaliteit (lichamelijk en geestelijk) > Werk-privé-balans' #aml.top_k_delta_effects(k=1)['feature'].to_list()[0]\n",
    "fig_feature = plt.effect_bar_verloop(\n",
    "    theme_name=feature_name, flip_colors=False,\n",
    "  #custom_thema_title= \"Persoonlijke ontwikkeling\",\n",
    "  x_name = 'verzuim frequentie'\n",
    ") \n",
    "\n",
    "fig_effect.show()\n",
    "fig_importance.show()\n",
    "fig_feature.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
